{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b707c5c0c271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mword2id_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word2id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mX_train_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b707c5c0c271>\u001b[0m in \u001b[0;36mget_word2id\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word2id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# input: list of tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# flat list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mword2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "DATA_DIR = '../../data/kftt-data-1.0/data/orig/'\n",
    "\n",
    "columns = ('ja', 'en', 'ja_orig', 'en_orig')\n",
    "train = pd.read_csv('%skyoto-%s.pairs' % (DATA_DIR, 'train'), names=columns)\n",
    "\n",
    "\n",
    "'''\n",
    "1. enとjaそれぞれword2idとid2wordを作る : 2回以上出てくる単語のみidを振り，それ以外は2にする．\n",
    "2. 日本語が10単語以上の文は削除する．\n",
    "3. tokensをidに変える．文頭と文末に0(sos), 1(eos)を追加する\n",
    "4. lengsを保存する\n",
    "5. paddingする\n",
    "'''\n",
    "\n",
    "\n",
    "def get_word2id(tokens):  # input: list of tokens\n",
    "    tokens = sum(tokens, [])  # flat list\n",
    "    counter = Counter(tokens)\n",
    "    word2id = {}\n",
    "    for index, (token, freq) in enumerate(counter.most_common(), 1):\n",
    "        if freq < 2:\n",
    "            word2id[token] = 0\n",
    "        else:\n",
    "            word2id[token] = index\n",
    "    return word2id\n",
    "\n",
    "\n",
    "def encode(tokens, word2id, sos=0, eos=1, unk=2):\n",
    "    ids = [sos]\n",
    "    for token in tokens:\n",
    "        if token in word2id:\n",
    "            ids.append(word2id[token])\n",
    "        else:\n",
    "            ids.append(unk)\n",
    "    ids.append(eos)\n",
    "    leng = len(ids)\n",
    "    return ids, leng\n",
    "\n",
    "\n",
    "# tokens = train['ja'].values.tolist()\n",
    "# word2id_ja = get_word2id(tokens)\n",
    "# X_train_ja = train.ja.apply(encode)\n",
    "\n",
    "tokens = train['en'].values.tolist()\n",
    "word2id_en = get_word2id(tokens)\n",
    "X_train_en = train.en.apply(encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['雪舟', 'は', '号', 'で', '、', '15', '世紀', '後半', '...\n",
       "Name: ja, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
